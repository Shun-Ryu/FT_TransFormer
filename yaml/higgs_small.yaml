# Yaml file get Model Parameter and Architecture
fttransformer: 
  model : ft-transformer

  # Model Architecture
  activation : "reglu"
  attention_dropout : 0.2
  d_ffn_factor : 1.3333333333333
  d_token :  192
  ffn_dropout : 0.1
  initialization : "kaiming"
  n_heads : 8
  n_layers : 3
  prenormalization : true
  residual_dropout : 0.0

  # training info
  optim : AdamW
  lr : 1e-4
  weight_decay : 1e-05
  batchsize : 512
  epochs : 10000000
  fold : 0
  count : 0

  kv_compression : None
  kv_compression_sharing : None
  # 256 -> 1 GPU, 
  # description: Training DL model [ FT_Transformer ] for Tabular Data

resnet:
  model : resnet
  
  # Model Architecture
  activation : "relu"
  d : 266
  d_embedding : 0
  d_hidden_factor : 1.330457169042573
  hidden_dropout : 0.3473780108857106
  n_layers : 3
  normalization : "batchnorm"
  residual_dropout : 0.1478460640899281

  
  # training info
  optim : AdamW
  lr : 0.001377976313474588
  weight_decay : 0.0
  batchsize : 512
  epochs : 10000000
  fold : 0
  count : 0

  # description: Training DL model [ ResNet ] for Tabular Data