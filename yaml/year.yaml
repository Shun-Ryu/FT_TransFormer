# Yaml file get Model Parameter and Architecture
fttransformer: 
  model : ft-transformer

  # Model Architecture
  activation : "reglu"
  attention_dropout : 0.2
  d_ffn_factor : 1.3333333333333
  d_token :  192
  ffn_dropout : 0.1
  initialization : "kaiming"
  n_heads : 8
  n_layers : 3
  prenormalization : true
  residual_dropout : 0.0

  # training info
  optim : AdamW
  lr : 1e-4
  weight_decay : 1e-05
  batchsize : 1024
  epochs : 10000000
  fold : 0
  count : 0

  kv_compression : 0
  kv_compression_sharing : 0
  # 256 -> 1 GPU, 
  # description: Training DL model [ FT_Transformer ] for Tabular Data

resnet:
  model : resnet
  
  # Model Architecture
  activation : "relu"
  d : 467
  d_embedding : 0
  d_hidden_factor : 2.061832845752671
  hidden_dropout : 0.496305297137531
  n_layers : 3
  normalization : "batchnorm"
  residual_dropout : 0.04719482253220739

  
  # training info
  optim : AdamW
  lr : 1.716966464351664e-05
  weight_decay : 4.681426841176751e-06
  batchsize : 1024
  epochs : 10000000
  fold : 0
  count : 0

  # description: Training DL model [ ResNet ] for Tabular Data