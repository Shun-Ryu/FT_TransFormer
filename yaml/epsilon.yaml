# Yaml file get Model Parameter and Architecture
fttransformer: 
  model : ft-transformer

  # Model Architecture
  activation : "reglu"
  attention_dropout : 0.2
  d_ffn_factor : 1.3333333333333
  d_token :  192
  ffn_dropout : 0.1
  initialization : "kaiming"
  n_heads : 8
  n_layers : 3
  prenormalization : true
  residual_dropout : 0.0

  # training info
  optim : AdamW
  lr : 1e-4
  weight_decay : 1e-05
  batchsize : 1024
  epochs : 10000000
  fold : 0
  count : 0

  kv_compression : 0.064
  kv_compression_sharing : "handwise"
  # 256 -> 1 GPU, 
  # description: Training DL model [ FT_Transformer ] for Tabular Data

resnet:
  model : resnet
  
  # Model Architecture
  activation : "relu"
  d : 435
  d_embedding : 0
  d_hidden_factor : 1.368835604177844
  hidden_dropout : 0.4264710650465512
  n_layers : 15
  normalization : "batchnorm"
  residual_dropout : 0.3195318174561529
  
  # training info
  optim : AdamW
  lr : 1.003584725994316e-05
  weight_decay : 0.0
  batchsize : 1024
  epochs : 10000000
  fold : 0
  count : 0

  # description: Training DL model [ ResNet ] for Tabular Data